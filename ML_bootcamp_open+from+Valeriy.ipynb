{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:28: UserWarning: [Errno 2] No such file or directory.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "import pylab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import subprocess\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('x_test.csv',sep=';',header=None)\n",
    "x_train = pd.read_csv('x_train.csv',sep=';',header=None)\n",
    "y_train = pd.read_csv('y_train.csv',sep=';',header=None)\n",
    "df_X = pd.concat((x_train, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  113.,     0.,  1164.,     0.,     0.,  1521.,     0.,   581.,\n",
       "            0.,   110.]),\n",
       " array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYLcwecwss6kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1afc53550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "plt.hist(y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразуем в категориальные, если надо и объединяем\n",
    "This block is designed to produce a sparce matrix with encoded category features\n",
    "But for the sake of computation resourse - we will not do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#categ = [182,138,115,131,97,76,11,156,200,96]\n",
    "categ = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in categ:\n",
    "    df_X.rename(columns={i:'cat'+str(i)}, inplace=True)\n",
    "for i in xrange(df_X.shape[1]):\n",
    "    df_X.rename(columns={i:'cont'+str(i)}, inplace=True)\n",
    "sparse_data = []\n",
    "f_cat = [f for f in df_X.columns if 'cat' in f]\n",
    "for f in f_cat:\n",
    "    dummy = pd.get_dummies(df_X[f].astype('category'))\n",
    "    tmp = csr_matrix(dummy)\n",
    "    sparse_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_num = [f for f in df_X.columns if 'cont' in f]\n",
    "scaler = StandardScaler()\n",
    "tmp = csr_matrix(df_X[f_num])\n",
    "sparse_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dim train', (3489, 223))\n",
      "('Dim test', (2327, 223))\n"
     ]
    }
   ],
   "source": [
    "ntrain = x_train.shape[0]\n",
    "xtr_te = tmp.todense()\n",
    "xtrain = xtr_te[:ntrain, :]\n",
    "xtest = xtr_te[ntrain:, :]\n",
    "print('Dim train', xtrain.shape)\n",
    "print('Dim test', xtest.shape)\n",
    "reserved = xtr_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Есть ли категории\n",
    "Check for number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of distinct values in a column is (89, 182)\n",
      "Looks like there is  categorical features\n"
     ]
    }
   ],
   "source": [
    "cat = []\n",
    "cat_test = pd.DataFrame(reserved)\n",
    "for i in xrange(cat_test.shape[1]):\n",
    "    cat.append(((len(cat_test[i].unique())),i))\n",
    "print 'Minimum number of distinct values in a column is', (min(cat))\n",
    "if min(cat[0])>100:\n",
    "    print \"Looks like there is no categorical features\"\n",
    "else:\n",
    "    print \"Looks like there is  categorical features\"\n",
    "cat.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182, 115, 97, 138, 131, 76, 11, 156, 200, 96, 79, 10]\n"
     ]
    }
   ],
   "source": [
    "category = []\n",
    "for i in xrange(12):\n",
    "    category.append(cat[i][1])\n",
    "print category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обратим в дальнейшем внимание на фичи 182,115,97,138,131,76,11,156,200,96,79,10\n",
    "Focus on features  182,115,97,138,131,76,11,156,200,96,79,10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор фич (тяжелая часть, в оригинале xrange(100))  - для ускорения варьируем это число (чуть ниже даны уже подсчитанные данные)\n",
    "Check it with feature selection\n",
    "We can skip this block - the best features have been listed after it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('y_train.csv',sep=';',header=None)\n",
    "res = []\n",
    "c = 0\n",
    "for i in xrange(223):\n",
    "    xtr_te = reserved[:,i]\n",
    "    xtrain = xtr_te[:ntrain, :]\n",
    "    xtest = xtr_te[ntrain:, :]\n",
    "    v = 0\n",
    "    \n",
    "    for j in xrange(1):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(xtrain,y,test_size=0.3,stratify = y)\n",
    "\n",
    "        rfc = RandomForestClassifier(n_estimators=150,random_state=1342)\n",
    "        rfc.fit(X=X_train,y=y_train)\n",
    "        pred = rfc.predict(X_test )\n",
    "        v+= accuracy_score(y_test,pred)/1.0\n",
    "    res.append((v,i))\n",
    "    #print(v,i)\n",
    "    c+=1\n",
    "    if c % 50 ==0:\n",
    "        print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort(reverse=True)\n",
    "best = []\n",
    "for i in xrange(12):\n",
    "    best.append(res[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 76, 79, 96, 97, 115, 131, 138, 156, 182, 200]\n",
      "[10, 11, 76, 79, 96, 97, 115, 131, 138, 156, 182, 200]\n"
     ]
    }
   ],
   "source": [
    "best.sort()\n",
    "category.sort()\n",
    "\n",
    "print best\n",
    "print category\n",
    "#best = [138, 79, 182, 156, 11, 76, 200, 10, 96, 97, 115, 131] # already calculated\n",
    "#category = [182, 115, 97, 138, 131, 76, 11, 156, 200, 96, 79, 10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best result 0,6636 - первый блок с подбором можно опустить\n",
    "The first one here also can be skipped\n",
    "We are looking for the best number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result =[]\n",
    "for b in xrange(1):\n",
    "    #best = [138, 79, 182, 156, 11, 76, 200, 10, 96, 97, 115, 131, 135]     #gives slighty better result\n",
    "\n",
    "    for i in [250,300,350,400,450,500]:\n",
    "   \n",
    "        v = 0    \n",
    "        for j in xrange(10):\n",
    "            xtr_te = reserved[:,best]\n",
    "            \n",
    "\n",
    " \n",
    "            xtrain = xtr_te[:ntrain, :]\n",
    "            xtest = xtr_te[ntrain:, :]\n",
    "            X_train,X_test,y_train,y_test = train_test_split(xtrain,y,test_size=0.3,stratify=y)\n",
    "            \n",
    "            rfc = RandomForestClassifier(n_estimators=i,max_features=1,\n",
    "                                                             class_weight={0:27.7,1:3.1,2:2.24,3:6,4:32})\n",
    "            rfc.fit(X=X_train,y=y_train)\n",
    "            pred = rfc.predict(X_test )\n",
    "            \n",
    "            v+= accuracy_score(y_test,pred)/10.0\n",
    "        print (v,i)\n",
    "        result.append((v,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#best = [138, 79, 182, 156, 11, 76, 200, 10, 96, 97, 115, 131, 135]     #gives slighty better result\n",
    "\n",
    "xtr_te = reserved[:,best]\n",
    "xtrain = xtr_te[:ntrain, :]\n",
    "xtest = xtr_te[ntrain:, :]\n",
    "y = pd.read_csv('y_train.csv',sep=';',header=None)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=300,max_features=1,class_weight={0:27.7,1:3.1,2:2.24,3:6,4:32})\n",
    "rfc.fit(X=xtrain,y=y)\n",
    "pred = rfc.predict(xtest)\n",
    "df = pd.DataFrame(pred)\n",
    "df.to_csv('Random_Forest_66_best_2.csv',index=None,header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best result 0,6713781\n",
    "Sometimes it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#best = [138, 79, 182, 156, 11, 76, 200, 10, 96, 97, 115, 131]\n",
    "\n",
    "y = pd.read_csv('y_train.csv',sep=';',header=None)\n",
    "\n",
    "xtr_te = reserved[:,best]\n",
    "xtrain = xtr_te[:ntrain, :]\n",
    "xtest = xtr_te[ntrain:, :]\n",
    "y_pred =pd.read_csv('Random_Forest_66.csv',header = None)\n",
    "rzdel = 1400\n",
    "y_total = pd.concat((y,y_pred.ix[0:rzdel-1,:]),axis = 0)\n",
    "x_total = np.concatenate((xtrain,xtest[0:rzdel,:]),axis = 0)\n",
    "print y_total.shape\n",
    "print x_total.shape\n",
    "rfc = RandomForestClassifier(n_estimators=850,max_features=1,class_weight={0:27.7,1:2*3.1,2:2*2.24,3:2*6,4:32})\n",
    "rfc.fit(X=x_total,y=y_total)\n",
    "pred = rfc.predict(xtest[rzdel:,:])\n",
    "print pred.shape\n",
    "df = pd.DataFrame(pred)\n",
    "df.to_csv('RF_all_data_1000-2327.csv',index=None,header = None)\n",
    "y_total = pd.concat((y,y_pred.ix[rzdel:,:]),axis = 0)\n",
    "x_total = np.concatenate((xtrain,xtest[rzdel:,:]),axis = 0)\n",
    "print y_total.shape\n",
    "print x_total.shape\n",
    "rfc = RandomForestClassifier(n_estimators=850,max_features=1,class_weight={0:27.7,1:2*3.1,2:2*2.24,3:2*6,4:32})\n",
    "rfc.fit(X=x_total,y=y_total)\n",
    "pred = rfc.predict(xtest[:rzdel,:])\n",
    "print pred.shape\n",
    "df = pd.DataFrame(pred)\n",
    "df.to_csv('RF_all_data_0-1000.csv',index=None,header = None)\n",
    "y1 = pd.read_csv('RF_all_data_0-1000.csv',header=None)\n",
    "y2 = pd.read_csv('RF_all_data_1000-2327.csv',header=None)\n",
    "pred = pd.concat((y1,y2),axis = 0)\n",
    "pred.to_csv(\"RF_OF_TOTAL\" +str(rzdel)+'IMPROVED'+\".csv\",header=None,index = None)\n",
    "print (sum(pred.values - y_pred.values !=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets take another look for mean of every feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mn = np.zeros((223,1))\n",
    "for i in xrange(223):\n",
    "    mn[i] = np.mean(reserved[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  12.,  188.,    0.,    2.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   10.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    2.,    2.,    1.,    3.,    0.,    2.]),\n",
       " array([ -2.63161422e-03,   2.56344994e-01,   5.15321603e-01,\n",
       "          7.74298211e-01,   1.03327482e+00,   1.29225143e+00,\n",
       "          1.55122804e+00,   1.81020465e+00,   2.06918125e+00,\n",
       "          2.32815786e+00,   2.58713447e+00,   2.84611108e+00,\n",
       "          3.10508769e+00,   3.36406430e+00,   3.62304091e+00,\n",
       "          3.88201751e+00,   4.14099412e+00,   4.39997073e+00,\n",
       "          4.65894734e+00,   4.91792395e+00,   5.17690056e+00,\n",
       "          5.43587716e+00,   5.69485377e+00,   5.95383038e+00,\n",
       "          6.21280699e+00,   6.47178360e+00,   6.73076021e+00,\n",
       "          6.98973682e+00,   7.24871342e+00,   7.50769003e+00,\n",
       "          7.76666664e+00,   8.02564325e+00,   8.28461986e+00,\n",
       "          8.54359647e+00,   8.80257308e+00,   9.06154968e+00,\n",
       "          9.32052629e+00,   9.57950290e+00,   9.83847951e+00,\n",
       "          1.00974561e+01,   1.03564327e+01,   1.06154093e+01,\n",
       "          1.08743859e+01,   1.11333626e+01,   1.13923392e+01,\n",
       "          1.16513158e+01,   1.19102924e+01,   1.21692690e+01,\n",
       "          1.24282456e+01,   1.26872222e+01,   1.29461988e+01,\n",
       "          1.32051754e+01,   1.34641520e+01,   1.37231286e+01,\n",
       "          1.39821052e+01,   1.42410819e+01,   1.45000585e+01,\n",
       "          1.47590351e+01,   1.50180117e+01,   1.52769883e+01,\n",
       "          1.55359649e+01,   1.57949415e+01,   1.60539181e+01,\n",
       "          1.63128947e+01,   1.65718713e+01,   1.68308479e+01,\n",
       "          1.70898245e+01,   1.73488012e+01,   1.76077778e+01,\n",
       "          1.78667544e+01,   1.81257310e+01,   1.83847076e+01,\n",
       "          1.86436842e+01,   1.89026608e+01,   1.91616374e+01,\n",
       "          1.94206140e+01,   1.96795906e+01,   1.99385672e+01,\n",
       "          2.01975439e+01,   2.04565205e+01,   2.07154971e+01,\n",
       "          2.09744737e+01,   2.12334503e+01,   2.14924269e+01,\n",
       "          2.17514035e+01,   2.20103801e+01,   2.22693567e+01,\n",
       "          2.25283333e+01,   2.27873099e+01,   2.30462865e+01,\n",
       "          2.33052632e+01,   2.35642398e+01,   2.38232164e+01,\n",
       "          2.40821930e+01,   2.43411696e+01,   2.46001462e+01,\n",
       "          2.48591228e+01,   2.51180994e+01,   2.53770760e+01,\n",
       "          2.56360526e+01,   2.58950292e+01]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADh9JREFUeJzt3X2MZQV5x/HvD1ZNxUgpLTspUFbRKDG12DYEg0mvaVU0\nabAmpdo2ig0NSbWamCYF/9mlaRNpUhONsTQVzWK0CjQIJI0ggUmDCUgqW1Z5kbZZClQG0ogt4h/S\nffrHnIFxnd25c++M996H7yeZ7Lln7ssze+79ztlzXzZVhSSpr+NmPYAkaWcZeklqztBLUnOGXpKa\nM/SS1Jyhl6TmNg19ktOS3Jbk20kOJvnQsP6kJLckeTDJzUlOXHeZTyZ5KMmBJGfv5A8gSTq2cfbo\nnwU+UlWvA94IfCDJa4FLgVur6jXAbcBlAEneDpxZVa8GLgGu3JHJJUlj2TT0VfV4VR0Ylp8G7gdO\nAy4A9g9n2z+cZvjz6uH8dwEnJtm9zXNLksa0pWP0SfYAZwN3AruragVWfxkAazE/FXhk3cUeG9ZJ\nkmZg7NAneRlwHfDhYc/+yM9O8LMUJGkO7RrnTEl2sRr5z1fVDcPqlSS7q2olyRLwxLD+MeD0dRc/\nbVh35HX6i0GSJlBV2cr5x92j/yxwX1V9Yt26G4GLhuWLgBvWrX8vQJJzgafWDvFsMOzCfu3du3fm\nMzj/7Od4Ic6/yLN3mH8Sm+7RJzkP+APgYJJ7WD1E81HgCuCaJH8EPAxcOMT7n5K8I8m/AT8A3j/R\nZJKkbbFp6Kvq68DxR/n2bx3lMh+cZihJ0vbxnbETGo1Gsx5hKs4/W4s8/yLPDos//yQy6TGfqW84\nqVndtiQtqiTUDj0ZK0laUIZekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGfopLS3tIQlJWFraM+tx\nJOkn+IapKSXh+U9ozsQfOiRJ4/ANU5Kkn2DoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYM\nvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOG\nXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlD\nL0nNGXpJam7T0Ce5KslKknvXrdub5NEk3xy+zl/3vcuSPJTk/iRv3anBJUnjGWeP/nPA2zZY//Gq\n+tXh66sASc4CLgTOAt4OfDpJtm1aSdKWbRr6qroD+N4G39oo4BcAX6qqZ6vqEPAQcM5UE0qSpjLN\nMfoPJDmQ5DNJThzWnQo8su48jw3rJEkzsmvCy30a+IuqqiR/CfwNcPFWr2Tfvn3PLY9GI0aj0YTj\nSFJPy8vLLC8vT3UdqarNz5ScAdxUVa8/1veSXApUVV0xfO+rwN6qumuDy9U4tz3vVp+CWPs5Qoef\nSdL8SkJVbem5z3EP3YR1x+STLK373ruAbw3LNwLvTvLiJK8AXgV8YysDSZK216aHbpJ8ERgBJyf5\nT2Av8OYkZwOHgUPAJQBVdV+Sa4D7gB8Bf9Jit12SFthYh2525IY9dCNJW7aTh24kSQvK0EtSc4Ze\nkpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMv\nSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGX\npOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBL\nUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJam5TUOf5KokK0nuXbfupCS3JHkwyc1JTlz3vU8meSjJgSRn\n79TgkqTxjLNH/zngbUesuxS4tapeA9wGXAaQ5O3AmVX1auAS4MptnFWSNIFNQ19VdwDfO2L1BcD+\nYXn/cHpt/dXD5e4CTkyye3tGlSRNYtJj9KdU1QpAVT0OrMX8VOCRded7bFgnSZqRXdt0PTXJhfbt\n2/fc8mg0YjQabdM4ktTD8vIyy8vLU11HqjZvdJIzgJuq6vXD6fuBUVWtJFkCbq+qs5JcOSx/eTjf\nA8BvrO39H3GdNc5tz7skPP97LnT4mSTNryRUVbZymXEP3WT4WnMjcNGwfBFww7r17x2GORd4aqPI\nS5J+ejbdo0/yRWAEnAysAHuBrwDXAqcDDwMXVtVTw/k/BZwP/AB4f1V98yjX6x69JG3RJHv0Yx26\n2QmGXpK2bicP3UiSFpShl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1\nZ+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKa\nM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nN\nGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnO7prlwkkPA94HDwI+q\n6pwkJwFfBs4ADgEXVtX3p5xTkjShaffoDwOjqnpDVZ0zrLsUuLWqXgPcBlw25W1IkqYwbeizwXVc\nAOwflvcD75zyNiRJU5g29AXcnOTuJBcP63ZX1QpAVT0OnDLlbUiSpjDVMXrgvKr6bpJfAG5J8iCr\n8V/vyNPP2bdv33PLo9GI0Wg05TiS1Mvy8jLLy8tTXUeqjtrhrV1Rshd4GriY1eP2K0mWgNur6qwN\nzl/bdduzlITnf5eFDj+TpPmVhKrKVi4z8aGbJC9N8rJh+QTgrcBB4EbgouFs7wNumPQ2JEnTm3iP\nPskrgOtZ3Z3dBXyhqj6W5OeAa4DTgYdZfXnlUxtc3j16SdqiSfbot+3QzVYZeknaup/qoRtJ0mIw\n9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0Z\neklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYM\nvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDW3a9YDLKLDhw/zxBNPzHoMSRqL\ne/QTuPLKKzn99DN55St/ZdajSNKmDP0EnnzySZ599s/44Q8fnfUokrQpQy9JzRn6BbC0tIckJGFp\nac+sx5G0YHwydgGsrDwM1LCc2Q4jaeG4Ry9JzRl6SWrO0EtSc4ZekprbsdAnOT/JA0m+k+TPd+p2\nJEnHtiOhT3Ic8CngbcDrgPckee1O3NbsHJr1AFNZXl6e9QhTcf7ZWeTZYXX+F9pLlndqj/4c4KGq\neriqfgR8Cbhgh25rRg7NeoCpdHiwLrJFnn+RZ4fV+Z9/yXINy73tVOhPBR5Zd/rRYd0Lwgttb0Ga\nR2uPw+OPP2Gsx2Pnx61Pxk7gRS96Eccf/y1e/vJ3bvj9F9regmZvLVLdAjWNtcfh4cPP8Pzj8XEu\nv/zyY56/4+M2VbX9V5qcC+yrqvOH05cCVVVXrDvP9t+wJL0AVNWW3iK/U6E/HngQ+E3gu8A3gPdU\n1f3bfmOSpGPakc+6qar/S/JB4BZWDw9dZeQlaTZ2ZI9ekjQ/ZvpkbJK9SR5N8s3h6/xZzjOuRX4z\nWJJDSf41yT1JvjHreTaT5KokK0nuXbfupCS3JHkwyc1JTpzljMdylPkX5n6f5LQktyX5dpKDST40\nrF+IbbDB/H86rJ/7bZDkJUnuGh6rB5PsHdbvSXLn0J9/SLLpkZmZ7tEPg/9vVX18ZkNs0fBmsO+w\n+vzDfwF3A++uqgdmOtiYkvwH8GtV9b1ZzzKOJG8CngaurqrXD+uuAP67qv56+EV7UlVdOss5j+Yo\n8y/M/T7JErBUVQeSvAz4F1bfE/N+FmAbHGP+32MBtkGSl1bVM8Pznl8HPgx8BLiuqq5N8rfAgar6\nu2Ndzzy8vHLRPmB90d8MFuZju4+lqu4AjvyldAGwf1jeD2z8Otc5cJT5YUHu91X1eFUdGJafBu4H\nTmNBtsFR5l97T8/cb4OqemZYfAmrz6kW8GbgH4f1+4Hf2ex65uEB/4EkB5J8Zl7/+XeERX8zWAE3\nJ7k7yR/PepgJnVJVK7D6QAZOmfE8k1i0+z1J9gBnA3cCuxdtG6yb/65h1dxvgyTHJbkHeBz4GvDv\nwFNVdXg4y6PAL252PTse+iRfS3Lvuq+Dw5+/DXwaOLOqzmb1B5nrf0Y1cV5V/TrwDlbv6G+a9UDb\nYNFeUbBw9/vhsMd1wIeHPeMj/87nehtsMP9CbIOqOlxVb2D1X1HnABN9ZtiO/1eCVfWWMc/698BN\nOznLNnkM+KV1p08b1i2Eqvru8OeTSa5n9c5zx2yn2rKVJLuramU4BvvErAfaiqp6ct3Jub/fD0/2\nXQd8vqpuGFYvzDbYaP5F2wZV9T9JloE3Aj+b5Lhhr36s/sz6VTdL606+C/jWrGbZgruBVyU5I8mL\ngXcDN854prEkeemwZ0OSE4C3shh/5+HHj6feCFw0LL8PuOHIC8yZH5t/Ae/3nwXuq6pPrFu3SNvg\nJ+ZfhG2Q5OfXDikl+RngLcB9wO3A7w5nG+vvftavurma1WNmh1n9OMhL1o77zbPhpVif4Pk3g31s\nxiONJckrgOtZ/Wf2LuAL8z57ki8CI+BkYAXYC3wFuBY4HXgYuLCqnprVjMdylPnfzILc75OcB/wz\ncJC1D4KBj7L6bvdrmPNtcIz5f5853wZJfpnVJ1uPG76+XFV/NTyOvwScBNwD/OHwwpCjX5dvmJKk\n3ubhVTeSpB1k6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6Tm/h/CDxb7ppPhXwAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1ae309850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mn,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00263161422455 0\n",
      "-0.00088414445368 1\n",
      "-0.000202657951995 2\n",
      "0.00035606755815 3\n",
      "0.00135855125935 4\n",
      "0.160113347297 5\n",
      "0.486809021071 6\n",
      "0.488616998401 7\n",
      "0.489473628543 8\n",
      "0.490796335682 9\n",
      "0.491427564085 10\n",
      "0.49258888362 11\n",
      "0.493712918698 12\n",
      "0.494136377001 13\n",
      "0.494692371566 14\n",
      "0.495115185463 15\n",
      "0.495333628738 16\n",
      "0.495515659544 17\n",
      "0.49571827526 18\n",
      "0.495837409195 19\n",
      "0.495915950526 20\n",
      "0.496200734717 21\n",
      "0.496498450084 22\n",
      "0.496625314265 23\n",
      "0.4967919311 24\n",
      "0.497013254662 25\n",
      "0.497177998793 26\n",
      "0.49736595286 27\n",
      "0.497532437837 28\n",
      "0.497663746907 29\n",
      "0.49780921455 30\n",
      "0.497993689132 31\n",
      "0.498081459585 32\n",
      "0.498197640855 33\n",
      "0.498285121558 34\n",
      "0.498413930712 35\n",
      "0.49843778852 36\n",
      "0.498504026776 37\n",
      "0.498626833073 38\n",
      "0.498653222841 39\n",
      "0.498678270715 40\n",
      "0.498809329014 41\n",
      "0.498933911121 42\n",
      "0.499018594783 43\n",
      "0.499191009911 44\n",
      "0.499343209779 45\n",
      "0.499451028459 46\n",
      "0.499559276219 47\n",
      "0.499739203802 48\n",
      "0.500132231499 49\n",
      "0.500215543313 50\n",
      "0.500324405669 51\n",
      "0.500470960021 52\n",
      "0.500713772517 53\n",
      "0.500768150444 54\n",
      "0.500802712979 55\n",
      "0.501063791464 56\n",
      "0.501224427897 57\n",
      "0.501337564445 58\n",
      "0.501453482458 59\n",
      "0.501516615643 60\n",
      "0.501779574599 61\n",
      "0.501841350578 62\n",
      "0.502027724622 63\n",
      "0.502149846383 64\n",
      "0.502204642137 65\n",
      "0.502410593969 66\n",
      "0.50247168139 67\n",
      "0.502537897529 68\n",
      "0.502587452278 69\n",
      "0.502627291302 70\n",
      "0.502965129532 71\n",
      "0.503304362751 72\n",
      "0.503519653087 73\n",
      "0.503726156894 74\n",
      "0.503778470106 75\n",
      "0.503836792352 76\n",
      "0.504046538831 77\n",
      "0.504357022791 78\n",
      "0.504571002451 79\n",
      "0.504839670553 80\n",
      "0.505468425719 81\n",
      "0.50575549684 82\n",
      "0.505811490285 83\n",
      "0.506239403018 84\n",
      "0.506814120372 85\n",
      "0.507271095162 86\n",
      "0.507718977008 87\n",
      "0.508679488977 88\n",
      "0.509360520606 89\n",
      "0.764513227108 90\n",
      "2.96318309486 91\n",
      "2.99387911564 92\n",
      "3.00506109293 93\n",
      "3.01762632191 94\n",
      "3.03827480208 95\n",
      "24.4861729 96\n",
      "24.6335732442 97\n",
      "25.078199714 98\n",
      "25.349373492 99\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,100,1):\n",
    "    \n",
    "    print np.percentile(mn,i),i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WE have anomalies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than 0.6 9\n",
      "less than 0.4 10\n",
      "less than 0.4 11\n",
      "more than 0.6 14\n",
      "more than 0.6 24\n",
      "more than 0.6 25\n",
      "more than 0.6 38\n",
      "more than 0.6 39\n",
      "more than 0.6 44\n",
      "more than 0.6 48\n",
      "more than 0.6 50\n",
      "more than 0.6 53\n",
      "more than 0.6 56\n",
      "more than 0.6 65\n",
      "less than 0.4 76\n",
      "less than 0.4 79\n",
      "more than 0.6 80\n",
      "less than 0.4 96\n",
      "less than 0.4 97\n",
      "more than 0.6 100\n",
      "less than 0.4 115\n",
      "less than 0.4 131\n",
      "less than 0.4 138\n",
      "more than 0.6 149\n",
      "more than 0.6 151\n",
      "less than 0.4 156\n",
      "more than 0.6 159\n",
      "more than 0.6 166\n",
      "more than 0.6 173\n",
      "less than 0.4 182\n",
      "more than 0.6 189\n",
      "more than 0.6 194\n",
      "less than 0.4 200\n",
      "more than 0.6 202\n",
      "more than 0.6 203\n"
     ]
    }
   ],
   "source": [
    "less = []\n",
    "more = []\n",
    "for i in xrange(223):\n",
    "    if mn[i]>0.6:\n",
    "        print 'more than 0.6',i\n",
    "        more.append(i)\n",
    "    if mn[i]<0.4:\n",
    "        print 'less than 0.4',i\n",
    "        less.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 76, 79, 96, 97, 115, 131, 138, 156, 182, 200]\n",
      "[10, 11, 76, 79, 96, 97, 115, 131, 138, 156, 182, 200]\n",
      "[10, 11, 76, 79, 96, 97, 115, 131, 138, 156, 182, 200]\n"
     ]
    }
   ],
   "source": [
    "less.sort()\n",
    "best.sort()\n",
    "category.sort()\n",
    "more.sort()\n",
    "print less\n",
    "print best\n",
    "print category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i would bet on  [10, 11, 76, 79, 96, 97, 115, 131, 138, 156, 182, 200]\n",
    "# also features in list called more are worth some consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = reserved[:,less]\n",
    "new_feature = pd.DataFrame(new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "umnogat = new_feature.copy()\n",
    "delit = new_feature.copy()\n",
    "plus = new_feature.copy()\n",
    "minus = new_feature.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 12\n",
    "for i in xrange(12):\n",
    "    for j in xrange(12):\n",
    "        umnogat[c] = umnogat[i] * umnogat[j]\n",
    "        c+=1\n",
    "umnogat = umnogat.T.drop_duplicates().T        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 12\n",
    "for i in xrange(12):\n",
    "    for j in xrange(12):\n",
    "        delit[c] = delit[i] / (delit[j]+0.0001)\n",
    "        c+=1\n",
    "delit = delit.T.drop_duplicates().T        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 12\n",
    "for i in xrange(12):\n",
    "    for j in xrange(12):\n",
    "        plus[c] = plus[i] + plus[j]\n",
    "        c+=1\n",
    "plus = plus.T.drop_duplicates().T        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 12\n",
    "for i in xrange(12):\n",
    "    for j in xrange(12):\n",
    "        minus[c] = minus[i] - minus[j]\n",
    "        c+=1\n",
    "minus = minus.T.drop_duplicates().T        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = pd.concat((umnogat,delit,plus,minus),axis=1)\n",
    "total = np.array(total)\n",
    "df = pd.DataFrame(total)\n",
    "remove = []\n",
    "cols = df.columns\n",
    "for i in range(len(cols)-1):\n",
    "    v = df[cols[i]].values\n",
    "    for j in range(i+1,len(cols)):\n",
    "        if np.array_equal(v,df[cols[j]].values):\n",
    "            remove.append(cols[j])\n",
    "\n",
    "df.drop(remove, axis=1, inplace=True)\n",
    "total = np.array(df)\n",
    "df.to_csv('feature_gen.csv',header=None,index=None)\n",
    "y = pd.read_csv('y_train.csv',sep=';',header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = pd.DataFrame(total)\n",
    "train_df = pd.DataFrame(total[:ntrain,:])\n",
    "test_df = pd.DataFrame(total[ntrain:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of  train+test (5816, 445)\n",
      "shape of  train+test without duplicates (5042, 445)\n",
      "shape of  train (3489, 445)\n",
      "shape of  train without duplicates (3183, 445)\n",
      "shape of  test (2327, 445)\n",
      "shape of  test without duplicates (2327, 445)\n"
     ]
    }
   ],
   "source": [
    "print 'shape of ', 'train+test', train_test_df.shape\n",
    "print 'shape of ', 'train+test without duplicates', train_test_df.drop_duplicates().shape\n",
    "print 'shape of ', 'train', train_df.shape\n",
    "print 'shape of ', 'train without duplicates', train_df.drop_duplicates().shape\n",
    "print 'shape of ', 'test', test_df.shape\n",
    "print 'shape of ', 'test without duplicates', test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('y_train.csv',sep=';',header=None)\n",
    "y.rename(columns={0:'y'},inplace=True)\n",
    "train_df = pd.concat((train_df,y),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates()\n",
    "y = train_df['y']\n",
    "train_df.drop('y',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5510, 445)\n"
     ]
    }
   ],
   "source": [
    "train_np = np.array(train_df)\n",
    "test_np = np.array(test_df)\n",
    "np_train = train_np.shape[0]\n",
    "total_new = np.concatenate((train_np,test_np),axis = 0)\n",
    "print total_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5510, 445)\n"
     ]
    }
   ],
   "source": [
    "total_new = np.concatenate((train_np,test_np),axis = 0)\n",
    "print total_new.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I would suggest to work on without dublicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr_te = total_new\n",
    "xtrain = xtr_te[:np_train, :]\n",
    "xtest = xtr_te[np_train:, :]\n",
    "split_test = np.random.choice(range(1, np_train), 900,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = np.array(y)\n",
    "X_test = xtrain[split_test,:]\n",
    "X_train = np.delete(xtrain, split_test, axis=0)\n",
    "y_test = y[split_test]\n",
    "y_train = np.delete(y, split_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Validations set\n",
    "#### We can play around with number of clusters feature to remove and so on \n",
    "Try it"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "feat_reduced = list(np.arange(total.shape[1]))\n",
    "#feat_reduced.remove(259)\n",
    "#feat_reduced.remove(261)\n",
    "#feat_reduced.remove(87)\n",
    "\n",
    "result =[]\n",
    "for ii in feat_reduced:\n",
    "    feat = list(np.arange(total.shape[1]))\n",
    "    #feat.remove(111)\n",
    "    #feat.remove(261)\n",
    "    #feat.remove(87)\n",
    "\n",
    "    feat.remove(ii)\n",
    "    xtr_te = total_new[:,feat]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=5, random_state=0).fit(xtr_te)\n",
    "    labels = kmeans.labels_.reshape(total_new.shape[0],1)\n",
    "\n",
    "\n",
    "    xtr_te = np.concatenate((xtr_te,labels),axis = 1)\n",
    "\n",
    "    xtrain = xtr_te[:np_train, :]\n",
    "    xtest = xtr_te[np_train:, :]\n",
    "    \n",
    "    X_test = xtrain[split_test,:]\n",
    "    X_train = np.delete(xtrain, split_test, axis=0)\n",
    "    y_test = y[split_test]\n",
    "    y_train = np.delete(y, split_test, axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for b in xrange(1):\n",
    "\n",
    "        for i in [200]:\n",
    "\n",
    "            v = 0    \n",
    "            for j in xrange(1):\n",
    "\n",
    "\n",
    "                rfc = RandomForestClassifier(n_estimators=i,random_state=1342,\n",
    "                                                                 class_weight={0:27.7,1:3.1,2:2.24,3:6,4:32})\n",
    "                rfc.fit(X=X_train,y=y_train)\n",
    "                pred = rfc.predict(X_test )\n",
    "                v+= accuracy_score(y_test,pred)/1.0\n",
    "            print ('score',v,'feature removed',ii)\n",
    "            result.append((v,ii))    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feat = list(np.arange(total.shape[1]))\n",
    "feat.remove(111)\n",
    "xtr_te = total_new[:,feat]\n",
    "    \n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(xtr_te)\n",
    "labels = kmeans.labels_.reshape(total_new.shape[0],1)\n",
    "\n",
    "\n",
    "xtr_te = np.concatenate((xtr_te,labels),axis = 1)\n",
    "\n",
    "xtrain = xtr_te[:np_train, :]\n",
    "xtest = xtr_te[np_train:, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "rfc = RandomForestClassifier(n_estimators=350,random_state=13,class_weight={0:27.7,1:3.1,2:2.24,3:6,4:32})\n",
    "rfc.fit(X=xtrain,y=y)\n",
    "pred = rfc.predict(xtest)\n",
    "df = pd.DataFrame(pred)\n",
    "df.to_csv('rf_test.csv',index=None,header = None)\n",
    "#df3 = pd.read_csv('RF_dop (2).csv',header=None)\n",
    "#print sum(df3.values != df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr_te = total\n",
    "xtrain = xtr_te[:ntrain, :]\n",
    "xtest = xtr_te[ntrain:, :]\n",
    "split_test = np.random.choice(range(1, np_train), 1000,replace=False)\n",
    "y = pd.read_csv('y_train.csv',sep=';',header=None)\n",
    "y = np.array(y)\n",
    "X_test = xtrain[split_test,:]\n",
    "X_train = np.delete(xtrain, split_test, axis=0)\n",
    "y_test = y[split_test]\n",
    "y_train = np.delete(y, split_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3489, 445)\n",
      "(2327, 445)\n"
     ]
    }
   ],
   "source": [
    "print xtrain.shape\n",
    "print xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:48: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('score', 0.63300000000000001, 'feature removed', 0)\n",
      "('score', 0.64300000000000002, 'feature removed', 1)\n",
      "('score', 0.64700000000000002, 'feature removed', 2)\n",
      "('score', 0.63600000000000001, 'feature removed', 3)\n",
      "('score', 0.64000000000000001, 'feature removed', 4)\n",
      "('score', 0.64000000000000001, 'feature removed', 5)\n",
      "('score', 0.64000000000000001, 'feature removed', 6)\n",
      "('score', 0.64300000000000002, 'feature removed', 7)\n",
      "('score', 0.64100000000000001, 'feature removed', 8)\n",
      "('score', 0.63300000000000001, 'feature removed', 9)\n",
      "('score', 0.63400000000000001, 'feature removed', 10)\n",
      "('score', 0.63200000000000001, 'feature removed', 11)\n",
      "('score', 0.63500000000000001, 'feature removed', 12)\n",
      "('score', 0.63800000000000001, 'feature removed', 13)\n",
      "('score', 0.63400000000000001, 'feature removed', 14)\n",
      "('score', 0.63500000000000001, 'feature removed', 15)\n",
      "('score', 0.63600000000000001, 'feature removed', 16)\n",
      "('score', 0.63600000000000001, 'feature removed', 17)\n",
      "('score', 0.629, 'feature removed', 18)\n",
      "('score', 0.63700000000000001, 'feature removed', 19)\n",
      "('score', 0.63, 'feature removed', 20)\n",
      "('score', 0.63700000000000001, 'feature removed', 21)\n",
      "('score', 0.63100000000000001, 'feature removed', 22)\n",
      "('score', 0.63900000000000001, 'feature removed', 23)\n",
      "('score', 0.63800000000000001, 'feature removed', 24)\n",
      "('score', 0.64400000000000002, 'feature removed', 25)\n",
      "('score', 0.63300000000000001, 'feature removed', 26)\n",
      "('score', 0.63900000000000001, 'feature removed', 27)\n",
      "('score', 0.63800000000000001, 'feature removed', 28)\n",
      "('score', 0.64100000000000001, 'feature removed', 29)\n",
      "('score', 0.63400000000000001, 'feature removed', 30)\n",
      "('score', 0.63300000000000001, 'feature removed', 31)\n",
      "('score', 0.63400000000000001, 'feature removed', 32)\n",
      "('score', 0.63100000000000001, 'feature removed', 33)\n",
      "('score', 0.64500000000000002, 'feature removed', 34)\n",
      "('score', 0.63800000000000001, 'feature removed', 35)\n",
      "('score', 0.63200000000000001, 'feature removed', 36)\n",
      "('score', 0.63200000000000001, 'feature removed', 37)\n",
      "('score', 0.64000000000000001, 'feature removed', 38)\n",
      "('score', 0.63300000000000001, 'feature removed', 39)\n",
      "('score', 0.63, 'feature removed', 40)\n",
      "('score', 0.64100000000000001, 'feature removed', 41)\n",
      "('score', 0.63500000000000001, 'feature removed', 42)\n",
      "('score', 0.64000000000000001, 'feature removed', 43)\n",
      "('score', 0.63900000000000001, 'feature removed', 44)\n",
      "('score', 0.64100000000000001, 'feature removed', 45)\n",
      "('score', 0.63500000000000001, 'feature removed', 46)\n",
      "('score', 0.64300000000000002, 'feature removed', 47)\n",
      "('score', 0.63400000000000001, 'feature removed', 48)\n",
      "('score', 0.63900000000000001, 'feature removed', 49)\n",
      "('score', 0.64200000000000002, 'feature removed', 50)\n",
      "('score', 0.63800000000000001, 'feature removed', 51)\n",
      "('score', 0.64500000000000002, 'feature removed', 52)\n",
      "('score', 0.63400000000000001, 'feature removed', 53)\n",
      "('score', 0.64200000000000002, 'feature removed', 54)\n",
      "('score', 0.64400000000000002, 'feature removed', 55)\n",
      "('score', 0.63400000000000001, 'feature removed', 56)\n",
      "('score', 0.64900000000000002, 'feature removed', 57)\n",
      "('score', 0.64800000000000002, 'feature removed', 58)\n",
      "('score', 0.64500000000000002, 'feature removed', 59)\n",
      "('score', 0.64500000000000002, 'feature removed', 60)\n",
      "('score', 0.64500000000000002, 'feature removed', 61)\n",
      "('score', 0.64300000000000002, 'feature removed', 62)\n",
      "('score', 0.64800000000000002, 'feature removed', 63)\n",
      "('score', 0.64500000000000002, 'feature removed', 64)\n",
      "('score', 0.63700000000000001, 'feature removed', 65)\n",
      "('score', 0.63600000000000001, 'feature removed', 66)\n",
      "('score', 0.64200000000000002, 'feature removed', 67)\n",
      "('score', 0.63100000000000001, 'feature removed', 68)\n",
      "('score', 0.63800000000000001, 'feature removed', 69)\n",
      "('score', 0.63800000000000001, 'feature removed', 70)\n",
      "('score', 0.64200000000000002, 'feature removed', 71)\n",
      "('score', 0.64000000000000001, 'feature removed', 72)\n",
      "('score', 0.63300000000000001, 'feature removed', 73)\n",
      "('score', 0.63600000000000001, 'feature removed', 74)\n",
      "('score', 0.63600000000000001, 'feature removed', 75)\n",
      "('score', 0.628, 'feature removed', 76)\n",
      "('score', 0.63600000000000001, 'feature removed', 77)\n",
      "('score', 0.628, 'feature removed', 78)\n",
      "('score', 0.63400000000000001, 'feature removed', 79)\n",
      "('score', 0.629, 'feature removed', 80)\n",
      "('score', 0.626, 'feature removed', 81)\n",
      "('score', 0.63, 'feature removed', 82)\n",
      "('score', 0.63100000000000001, 'feature removed', 83)\n",
      "('score', 0.626, 'feature removed', 84)\n",
      "('score', 0.625, 'feature removed', 85)\n",
      "('score', 0.63400000000000001, 'feature removed', 86)\n",
      "('score', 0.625, 'feature removed', 87)\n",
      "('score', 0.63200000000000001, 'feature removed', 88)\n",
      "('score', 0.63400000000000001, 'feature removed', 89)\n",
      "('score', 0.63100000000000001, 'feature removed', 90)\n",
      "('score', 0.63600000000000001, 'feature removed', 91)\n",
      "('score', 0.63600000000000001, 'feature removed', 92)\n",
      "('score', 0.63700000000000001, 'feature removed', 93)\n",
      "('score', 0.63400000000000001, 'feature removed', 94)\n",
      "('score', 0.63500000000000001, 'feature removed', 95)\n",
      "('score', 0.63300000000000001, 'feature removed', 96)\n",
      "('score', 0.63500000000000001, 'feature removed', 97)\n",
      "('score', 0.63700000000000001, 'feature removed', 98)\n",
      "('score', 0.629, 'feature removed', 99)\n",
      "('score', 0.63100000000000001, 'feature removed', 100)\n",
      "('score', 0.63500000000000001, 'feature removed', 101)\n",
      "('score', 0.64000000000000001, 'feature removed', 102)\n",
      "('score', 0.63400000000000001, 'feature removed', 103)\n",
      "('score', 0.63400000000000001, 'feature removed', 104)\n",
      "('score', 0.628, 'feature removed', 105)\n",
      "('score', 0.63600000000000001, 'feature removed', 106)\n",
      "('score', 0.64200000000000002, 'feature removed', 107)\n",
      "('score', 0.63100000000000001, 'feature removed', 108)\n",
      "('score', 0.63900000000000001, 'feature removed', 109)\n",
      "('score', 0.63600000000000001, 'feature removed', 110)\n",
      "('score', 0.63400000000000001, 'feature removed', 111)\n",
      "('score', 0.63700000000000001, 'feature removed', 112)\n",
      "('score', 0.63700000000000001, 'feature removed', 113)\n",
      "('score', 0.64400000000000002, 'feature removed', 114)\n",
      "('score', 0.63600000000000001, 'feature removed', 115)\n",
      "('score', 0.64600000000000002, 'feature removed', 116)\n",
      "('score', 0.63200000000000001, 'feature removed', 117)\n",
      "('score', 0.63800000000000001, 'feature removed', 118)\n",
      "('score', 0.63600000000000001, 'feature removed', 119)\n",
      "('score', 0.64600000000000002, 'feature removed', 120)\n",
      "('score', 0.64400000000000002, 'feature removed', 121)\n",
      "('score', 0.64100000000000001, 'feature removed', 122)\n",
      "('score', 0.64500000000000002, 'feature removed', 123)\n",
      "('score', 0.63100000000000001, 'feature removed', 124)\n",
      "('score', 0.63, 'feature removed', 125)\n",
      "('score', 0.63700000000000001, 'feature removed', 126)\n",
      "('score', 0.63200000000000001, 'feature removed', 127)\n",
      "('score', 0.63900000000000001, 'feature removed', 128)\n",
      "('score', 0.64200000000000002, 'feature removed', 129)\n",
      "('score', 0.63300000000000001, 'feature removed', 130)\n",
      "('score', 0.63900000000000001, 'feature removed', 131)\n",
      "('score', 0.628, 'feature removed', 132)\n",
      "('score', 0.64000000000000001, 'feature removed', 133)\n",
      "('score', 0.63, 'feature removed', 134)\n",
      "('score', 0.626, 'feature removed', 135)\n",
      "('score', 0.63300000000000001, 'feature removed', 136)\n",
      "('score', 0.626, 'feature removed', 137)\n",
      "('score', 0.63300000000000001, 'feature removed', 138)\n",
      "('score', 0.63100000000000001, 'feature removed', 139)\n",
      "('score', 0.63500000000000001, 'feature removed', 140)\n",
      "('score', 0.63300000000000001, 'feature removed', 141)\n",
      "('score', 0.628, 'feature removed', 142)\n",
      "('score', 0.63900000000000001, 'feature removed', 143)\n",
      "('score', 0.63200000000000001, 'feature removed', 144)\n",
      "('score', 0.63600000000000001, 'feature removed', 145)\n",
      "('score', 0.63600000000000001, 'feature removed', 146)\n",
      "('score', 0.627, 'feature removed', 147)\n",
      "('score', 0.63100000000000001, 'feature removed', 148)\n",
      "('score', 0.63700000000000001, 'feature removed', 149)\n",
      "('score', 0.63500000000000001, 'feature removed', 150)\n",
      "('score', 0.64200000000000002, 'feature removed', 151)\n",
      "('score', 0.64200000000000002, 'feature removed', 152)\n",
      "('score', 0.63600000000000001, 'feature removed', 153)\n",
      "('score', 0.63700000000000001, 'feature removed', 154)\n",
      "('score', 0.63200000000000001, 'feature removed', 155)\n",
      "('score', 0.63300000000000001, 'feature removed', 156)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('score', 0.63300000000000001, 'feature removed', 157)\n",
      "('score', 0.63300000000000001, 'feature removed', 158)\n",
      "('score', 0.63400000000000001, 'feature removed', 159)\n",
      "('score', 0.63, 'feature removed', 160)\n",
      "('score', 0.63100000000000001, 'feature removed', 161)\n",
      "('score', 0.63200000000000001, 'feature removed', 162)\n",
      "('score', 0.64300000000000002, 'feature removed', 163)\n",
      "('score', 0.63900000000000001, 'feature removed', 164)\n",
      "('score', 0.63500000000000001, 'feature removed', 165)\n",
      "('score', 0.63600000000000001, 'feature removed', 166)\n",
      "('score', 0.63600000000000001, 'feature removed', 167)\n",
      "('score', 0.63600000000000001, 'feature removed', 168)\n",
      "('score', 0.64100000000000001, 'feature removed', 169)\n",
      "('score', 0.63400000000000001, 'feature removed', 170)\n",
      "('score', 0.625, 'feature removed', 171)\n",
      "('score', 0.63600000000000001, 'feature removed', 172)\n",
      "('score', 0.63900000000000001, 'feature removed', 173)\n",
      "('score', 0.63500000000000001, 'feature removed', 174)\n",
      "('score', 0.64000000000000001, 'feature removed', 175)\n",
      "('score', 0.63300000000000001, 'feature removed', 176)\n",
      "('score', 0.63700000000000001, 'feature removed', 177)\n",
      "('score', 0.63600000000000001, 'feature removed', 178)\n",
      "('score', 0.64400000000000002, 'feature removed', 179)\n",
      "('score', 0.64400000000000002, 'feature removed', 180)\n",
      "('score', 0.63800000000000001, 'feature removed', 181)\n",
      "('score', 0.63600000000000001, 'feature removed', 182)\n",
      "('score', 0.63700000000000001, 'feature removed', 183)\n",
      "('score', 0.64400000000000002, 'feature removed', 184)\n",
      "('score', 0.64000000000000001, 'feature removed', 185)\n",
      "('score', 0.64000000000000001, 'feature removed', 186)\n",
      "('score', 0.63900000000000001, 'feature removed', 187)\n",
      "('score', 0.63900000000000001, 'feature removed', 188)\n",
      "('score', 0.64000000000000001, 'feature removed', 189)\n",
      "('score', 0.64400000000000002, 'feature removed', 190)\n",
      "('score', 0.64200000000000002, 'feature removed', 191)\n",
      "('score', 0.63500000000000001, 'feature removed', 192)\n",
      "('score', 0.63700000000000001, 'feature removed', 193)\n",
      "('score', 0.63700000000000001, 'feature removed', 194)\n",
      "('score', 0.64500000000000002, 'feature removed', 195)\n",
      "('score', 0.63700000000000001, 'feature removed', 196)\n",
      "('score', 0.63400000000000001, 'feature removed', 197)\n",
      "('score', 0.626, 'feature removed', 198)\n",
      "('score', 0.629, 'feature removed', 199)\n",
      "('score', 0.63200000000000001, 'feature removed', 200)\n",
      "('score', 0.64100000000000001, 'feature removed', 201)\n",
      "('score', 0.63700000000000001, 'feature removed', 202)\n",
      "('score', 0.63600000000000001, 'feature removed', 203)\n",
      "('score', 0.63100000000000001, 'feature removed', 204)\n",
      "('score', 0.63900000000000001, 'feature removed', 205)\n",
      "('score', 0.63, 'feature removed', 206)\n",
      "('score', 0.64000000000000001, 'feature removed', 207)\n",
      "('score', 0.63400000000000001, 'feature removed', 208)\n",
      "('score', 0.63600000000000001, 'feature removed', 209)\n",
      "('score', 0.63900000000000001, 'feature removed', 210)\n",
      "('score', 0.63100000000000001, 'feature removed', 211)\n",
      "('score', 0.63300000000000001, 'feature removed', 212)\n",
      "('score', 0.63400000000000001, 'feature removed', 213)\n",
      "('score', 0.63500000000000001, 'feature removed', 214)\n",
      "('score', 0.63800000000000001, 'feature removed', 215)\n",
      "('score', 0.63700000000000001, 'feature removed', 216)\n",
      "('score', 0.63600000000000001, 'feature removed', 217)\n",
      "('score', 0.628, 'feature removed', 218)\n",
      "('score', 0.63800000000000001, 'feature removed', 219)\n",
      "('score', 0.63700000000000001, 'feature removed', 220)\n",
      "('score', 0.63300000000000001, 'feature removed', 221)\n",
      "('score', 0.63400000000000001, 'feature removed', 222)\n",
      "('score', 0.63100000000000001, 'feature removed', 223)\n",
      "('score', 0.63300000000000001, 'feature removed', 224)\n",
      "('score', 0.627, 'feature removed', 225)\n",
      "('score', 0.63200000000000001, 'feature removed', 226)\n",
      "('score', 0.63200000000000001, 'feature removed', 227)\n",
      "('score', 0.63700000000000001, 'feature removed', 228)\n",
      "('score', 0.64200000000000002, 'feature removed', 229)\n",
      "('score', 0.63800000000000001, 'feature removed', 230)\n",
      "('score', 0.63700000000000001, 'feature removed', 231)\n",
      "('score', 0.63900000000000001, 'feature removed', 232)\n",
      "('score', 0.64300000000000002, 'feature removed', 233)\n",
      "('score', 0.64000000000000001, 'feature removed', 234)\n",
      "('score', 0.628, 'feature removed', 235)\n",
      "('score', 0.63800000000000001, 'feature removed', 236)\n",
      "('score', 0.63100000000000001, 'feature removed', 237)\n",
      "('score', 0.63400000000000001, 'feature removed', 238)\n",
      "('score', 0.624, 'feature removed', 239)\n",
      "('score', 0.629, 'feature removed', 240)\n",
      "('score', 0.63900000000000001, 'feature removed', 241)\n",
      "('score', 0.63100000000000001, 'feature removed', 242)\n",
      "('score', 0.63400000000000001, 'feature removed', 243)\n",
      "('score', 0.629, 'feature removed', 244)\n",
      "('score', 0.627, 'feature removed', 245)\n",
      "('score', 0.63400000000000001, 'feature removed', 246)\n",
      "('score', 0.63700000000000001, 'feature removed', 247)\n",
      "('score', 0.64000000000000001, 'feature removed', 248)\n",
      "('score', 0.63500000000000001, 'feature removed', 249)\n",
      "('score', 0.63800000000000001, 'feature removed', 250)\n",
      "('score', 0.63600000000000001, 'feature removed', 251)\n",
      "('score', 0.63500000000000001, 'feature removed', 252)\n",
      "('score', 0.63200000000000001, 'feature removed', 253)\n",
      "('score', 0.63900000000000001, 'feature removed', 254)\n",
      "('score', 0.63500000000000001, 'feature removed', 255)\n",
      "('score', 0.64100000000000001, 'feature removed', 256)\n",
      "('score', 0.64000000000000001, 'feature removed', 257)\n",
      "('score', 0.64600000000000002, 'feature removed', 258)\n",
      "('score', 0.64100000000000001, 'feature removed', 259)\n",
      "('score', 0.63600000000000001, 'feature removed', 260)\n",
      "('score', 0.63800000000000001, 'feature removed', 261)\n",
      "('score', 0.63700000000000001, 'feature removed', 262)\n",
      "('score', 0.63700000000000001, 'feature removed', 263)\n",
      "('score', 0.63700000000000001, 'feature removed', 264)\n",
      "('score', 0.63900000000000001, 'feature removed', 265)\n",
      "('score', 0.63800000000000001, 'feature removed', 266)\n",
      "('score', 0.63100000000000001, 'feature removed', 267)\n",
      "('score', 0.63, 'feature removed', 268)\n",
      "('score', 0.63200000000000001, 'feature removed', 269)\n",
      "('score', 0.63900000000000001, 'feature removed', 270)\n",
      "('score', 0.63500000000000001, 'feature removed', 271)\n",
      "('score', 0.63300000000000001, 'feature removed', 272)\n",
      "('score', 0.63100000000000001, 'feature removed', 273)\n",
      "('score', 0.63400000000000001, 'feature removed', 274)\n",
      "('score', 0.64000000000000001, 'feature removed', 275)\n",
      "('score', 0.64300000000000002, 'feature removed', 276)\n",
      "('score', 0.63700000000000001, 'feature removed', 277)\n",
      "('score', 0.63900000000000001, 'feature removed', 278)\n",
      "('score', 0.63600000000000001, 'feature removed', 279)\n",
      "('score', 0.628, 'feature removed', 280)\n",
      "('score', 0.63500000000000001, 'feature removed', 281)\n",
      "('score', 0.63400000000000001, 'feature removed', 282)\n",
      "('score', 0.63600000000000001, 'feature removed', 283)\n",
      "('score', 0.64200000000000002, 'feature removed', 284)\n",
      "('score', 0.63800000000000001, 'feature removed', 285)\n",
      "('score', 0.63600000000000001, 'feature removed', 286)\n",
      "('score', 0.63100000000000001, 'feature removed', 287)\n",
      "('score', 0.63400000000000001, 'feature removed', 288)\n",
      "('score', 0.63300000000000001, 'feature removed', 289)\n",
      "('score', 0.63200000000000001, 'feature removed', 290)\n",
      "('score', 0.64300000000000002, 'feature removed', 291)\n",
      "('score', 0.63, 'feature removed', 292)\n",
      "('score', 0.63200000000000001, 'feature removed', 293)\n",
      "('score', 0.63, 'feature removed', 294)\n",
      "('score', 0.63400000000000001, 'feature removed', 295)\n",
      "('score', 0.63600000000000001, 'feature removed', 296)\n",
      "('score', 0.63100000000000001, 'feature removed', 297)\n",
      "('score', 0.64500000000000002, 'feature removed', 298)\n",
      "('score', 0.64200000000000002, 'feature removed', 299)\n",
      "('score', 0.64200000000000002, 'feature removed', 300)\n",
      "('score', 0.63900000000000001, 'feature removed', 301)\n",
      "('score', 0.64500000000000002, 'feature removed', 302)\n",
      "('score', 0.64100000000000001, 'feature removed', 303)\n",
      "('score', 0.64100000000000001, 'feature removed', 304)\n",
      "('score', 0.64600000000000002, 'feature removed', 305)\n",
      "('score', 0.63, 'feature removed', 306)\n",
      "('score', 0.63400000000000001, 'feature removed', 307)\n",
      "('score', 0.63700000000000001, 'feature removed', 308)\n",
      "('score', 0.63700000000000001, 'feature removed', 309)\n",
      "('score', 0.64200000000000002, 'feature removed', 310)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('score', 0.63300000000000001, 'feature removed', 311)\n",
      "('score', 0.63900000000000001, 'feature removed', 312)\n",
      "('score', 0.63500000000000001, 'feature removed', 313)\n",
      "('score', 0.64000000000000001, 'feature removed', 314)\n",
      "('score', 0.64200000000000002, 'feature removed', 315)\n",
      "('score', 0.63800000000000001, 'feature removed', 316)\n",
      "('score', 0.64300000000000002, 'feature removed', 317)\n",
      "('score', 0.63500000000000001, 'feature removed', 318)\n",
      "('score', 0.63400000000000001, 'feature removed', 319)\n",
      "('score', 0.63600000000000001, 'feature removed', 320)\n",
      "('score', 0.63600000000000001, 'feature removed', 321)\n",
      "('score', 0.64300000000000002, 'feature removed', 322)\n",
      "('score', 0.63500000000000001, 'feature removed', 323)\n",
      "('score', 0.63600000000000001, 'feature removed', 324)\n",
      "('score', 0.63200000000000001, 'feature removed', 325)\n",
      "('score', 0.64300000000000002, 'feature removed', 326)\n",
      "('score', 0.63300000000000001, 'feature removed', 327)\n",
      "('score', 0.63100000000000001, 'feature removed', 328)\n",
      "('score', 0.63100000000000001, 'feature removed', 329)\n",
      "('score', 0.63300000000000001, 'feature removed', 330)\n",
      "('score', 0.63, 'feature removed', 331)\n",
      "('score', 0.63, 'feature removed', 332)\n",
      "('score', 0.63300000000000001, 'feature removed', 333)\n",
      "('score', 0.63900000000000001, 'feature removed', 334)\n",
      "('score', 0.627, 'feature removed', 335)\n",
      "('score', 0.628, 'feature removed', 336)\n",
      "('score', 0.63900000000000001, 'feature removed', 337)\n",
      "('score', 0.63300000000000001, 'feature removed', 338)\n",
      "('score', 0.63, 'feature removed', 339)\n",
      "('score', 0.627, 'feature removed', 340)\n",
      "('score', 0.63200000000000001, 'feature removed', 341)\n",
      "('score', 0.629, 'feature removed', 342)\n",
      "('score', 0.63500000000000001, 'feature removed', 343)\n",
      "('score', 0.63900000000000001, 'feature removed', 344)\n",
      "('score', 0.63800000000000001, 'feature removed', 345)\n",
      "('score', 0.64100000000000001, 'feature removed', 346)\n",
      "('score', 0.64300000000000002, 'feature removed', 347)\n",
      "('score', 0.63500000000000001, 'feature removed', 348)\n",
      "('score', 0.63700000000000001, 'feature removed', 349)\n",
      "('score', 0.63, 'feature removed', 350)\n",
      "('score', 0.63, 'feature removed', 351)\n",
      "('score', 0.63600000000000001, 'feature removed', 352)\n",
      "('score', 0.63500000000000001, 'feature removed', 353)\n",
      "('score', 0.627, 'feature removed', 354)\n",
      "('score', 0.63400000000000001, 'feature removed', 355)\n",
      "('score', 0.63800000000000001, 'feature removed', 356)\n",
      "('score', 0.64100000000000001, 'feature removed', 357)\n",
      "('score', 0.63300000000000001, 'feature removed', 358)\n",
      "('score', 0.63700000000000001, 'feature removed', 359)\n",
      "('score', 0.63600000000000001, 'feature removed', 360)\n",
      "('score', 0.64100000000000001, 'feature removed', 361)\n",
      "('score', 0.64400000000000002, 'feature removed', 362)\n",
      "('score', 0.63500000000000001, 'feature removed', 363)\n",
      "('score', 0.63300000000000001, 'feature removed', 364)\n",
      "('score', 0.63300000000000001, 'feature removed', 365)\n",
      "('score', 0.628, 'feature removed', 366)\n",
      "('score', 0.625, 'feature removed', 367)\n",
      "('score', 0.629, 'feature removed', 368)\n",
      "('score', 0.63, 'feature removed', 369)\n",
      "('score', 0.63300000000000001, 'feature removed', 370)\n",
      "('score', 0.63900000000000001, 'feature removed', 371)\n",
      "('score', 0.64000000000000001, 'feature removed', 372)\n",
      "('score', 0.63700000000000001, 'feature removed', 373)\n",
      "('score', 0.629, 'feature removed', 374)\n",
      "('score', 0.63800000000000001, 'feature removed', 375)\n",
      "('score', 0.63700000000000001, 'feature removed', 376)\n",
      "('score', 0.63700000000000001, 'feature removed', 377)\n",
      "('score', 0.625, 'feature removed', 378)\n",
      "('score', 0.63800000000000001, 'feature removed', 379)\n",
      "('score', 0.63800000000000001, 'feature removed', 380)\n",
      "('score', 0.64000000000000001, 'feature removed', 381)\n",
      "('score', 0.63300000000000001, 'feature removed', 382)\n",
      "('score', 0.63900000000000001, 'feature removed', 383)\n",
      "('score', 0.63700000000000001, 'feature removed', 384)\n",
      "('score', 0.63900000000000001, 'feature removed', 385)\n",
      "('score', 0.64000000000000001, 'feature removed', 386)\n",
      "('score', 0.64500000000000002, 'feature removed', 387)\n",
      "('score', 0.64200000000000002, 'feature removed', 388)\n",
      "('score', 0.65000000000000002, 'feature removed', 389)\n",
      "('score', 0.63600000000000001, 'feature removed', 390)\n",
      "('score', 0.63400000000000001, 'feature removed', 391)\n",
      "('score', 0.629, 'feature removed', 392)\n",
      "('score', 0.63700000000000001, 'feature removed', 393)\n",
      "('score', 0.63500000000000001, 'feature removed', 394)\n",
      "('score', 0.63800000000000001, 'feature removed', 395)\n",
      "('score', 0.63800000000000001, 'feature removed', 396)\n",
      "('score', 0.63500000000000001, 'feature removed', 397)\n",
      "('score', 0.63900000000000001, 'feature removed', 398)\n",
      "('score', 0.63200000000000001, 'feature removed', 399)\n",
      "('score', 0.63700000000000001, 'feature removed', 400)\n",
      "('score', 0.63500000000000001, 'feature removed', 401)\n",
      "('score', 0.63700000000000001, 'feature removed', 402)\n",
      "('score', 0.63, 'feature removed', 403)\n",
      "('score', 0.63700000000000001, 'feature removed', 404)\n",
      "('score', 0.627, 'feature removed', 405)\n",
      "('score', 0.63100000000000001, 'feature removed', 406)\n",
      "('score', 0.626, 'feature removed', 407)\n",
      "('score', 0.627, 'feature removed', 408)\n",
      "('score', 0.63200000000000001, 'feature removed', 409)\n",
      "('score', 0.63900000000000001, 'feature removed', 410)\n",
      "('score', 0.63300000000000001, 'feature removed', 411)\n",
      "('score', 0.64200000000000002, 'feature removed', 412)\n",
      "('score', 0.63500000000000001, 'feature removed', 413)\n",
      "('score', 0.64000000000000001, 'feature removed', 414)\n",
      "('score', 0.63700000000000001, 'feature removed', 415)\n",
      "('score', 0.64000000000000001, 'feature removed', 416)\n",
      "('score', 0.63800000000000001, 'feature removed', 417)\n",
      "('score', 0.63700000000000001, 'feature removed', 418)\n",
      "('score', 0.63700000000000001, 'feature removed', 419)\n",
      "('score', 0.64000000000000001, 'feature removed', 420)\n",
      "('score', 0.63900000000000001, 'feature removed', 421)\n",
      "('score', 0.64300000000000002, 'feature removed', 422)\n",
      "('score', 0.64100000000000001, 'feature removed', 423)\n",
      "('score', 0.64100000000000001, 'feature removed', 424)\n",
      "('score', 0.63600000000000001, 'feature removed', 425)\n",
      "('score', 0.64000000000000001, 'feature removed', 426)\n",
      "('score', 0.64100000000000001, 'feature removed', 427)\n",
      "('score', 0.64200000000000002, 'feature removed', 428)\n",
      "('score', 0.64200000000000002, 'feature removed', 429)\n",
      "('score', 0.63800000000000001, 'feature removed', 430)\n",
      "('score', 0.64200000000000002, 'feature removed', 431)\n",
      "('score', 0.64900000000000002, 'feature removed', 432)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feat_reduced = list(np.arange(total.shape[1]))\n",
    "#feat_reduced.remove(259)\n",
    "#feat_reduced.remove(261)\n",
    "#feat_reduced.remove(87)\n",
    "\n",
    "result =[]\n",
    "for ii in feat_reduced:\n",
    "    feat = list(np.arange(total.shape[1]))\n",
    "    #feat.remove(111)\n",
    "    #feat.remove(261)\n",
    "    #feat.remove(87)\n",
    "\n",
    "    feat.remove(ii)\n",
    "    xtr_te = total[:,feat]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=5, random_state=0).fit(xtr_te)\n",
    "    labels = kmeans.labels_.reshape(total.shape[0],1)\n",
    "\n",
    "\n",
    "    xtr_te = np.concatenate((xtr_te,labels),axis = 1)\n",
    "\n",
    "    xtrain = xtr_te[:ntrain, :]\n",
    "    xtest = xtr_te[ntrain:, :]\n",
    "    \n",
    "    X_test = xtrain[split_test,:]\n",
    "    X_train = np.delete(xtrain, split_test, axis=0)\n",
    "    y_test = y[split_test]\n",
    "    y_train = np.delete(y, split_test, axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for b in xrange(1):\n",
    "\n",
    "        for i in [250]:\n",
    "\n",
    "            v = 0    \n",
    "            for j in xrange(1):\n",
    "\n",
    "\n",
    "                rfc = RandomForestClassifier(n_estimators=i,random_state=1342,\n",
    "                                                                 class_weight={0:27.7,1:3.1,2:2.24,3:6,4:32})\n",
    "                rfc.fit(X=X_train,y=y_train)\n",
    "                pred = rfc.predict(X_test )\n",
    "                v+= accuracy_score(y_test,pred)/1.0\n",
    "            print ('score',v,'feature removed',ii)\n",
    "            result.append((v,ii))    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = list(np.arange(total.shape[1]))\n",
    "feat.remove(111)\n",
    "xtr_te = total_new[:,feat]\n",
    "    \n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(xtr_te)\n",
    "labels = kmeans.labels_.reshape(total_new.shape[0],1)\n",
    "\n",
    "\n",
    "xtr_te = np.concatenate((xtr_te,labels),axis = 1)\n",
    "\n",
    "xtrain = xtr_te[:np_train, :]\n",
    "xtest = xtr_te[np_train:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('y_train.csv',sep=';',header=None)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=350,random_state=13,class_weight={0:27.7,1:3.1,2:2.24,3:6,4:32})\n",
    "rfc.fit(X=xtrain,y=y)\n",
    "pred = rfc.predict(xtest)\n",
    "df = pd.DataFrame(pred)\n",
    "df.to_csv('rf_test.csv',index=None,header = None)\n",
    "#df3 = pd.read_csv('RF_dop (2).csv',header=None)\n",
    "#print sum(df3.values != df.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
